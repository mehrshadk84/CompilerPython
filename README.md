# üöÄ Custom Compiler Frontend in Python

This repository contains a fully functional **Compiler Frontend** built from scratch using Python and the `PLY` (Python Lex-Yacc) library. It successfully implements the first three major phases of a compiler: Lexical Analysis, Syntax Analysis (with AST generation), and Semantic Analysis.

## üß† Core Components

### 1. Lexical Analyzer (Scanner)
The Lexer reads the raw source code and converts it into a stream of meaningful tokens. 
- Utilizes regular expressions to identify keywords, identifiers, operators, and literals (integers, floats, strings).
- Tracks line numbers for precise error reporting.
- Handles illegal character detection and gracefully reports lexical errors.

### 2. Syntax Analyzer (Parser) & üå≥ Abstract Syntax Tree (AST)
The Parser uses $LALR(1)$ parsing tables generated by PLY to validate the syntax based on a custom Context-Free Grammar (CFG).
**The real power of this phase is the AST Generation:**
Instead of just validating the grammar, each parser rule dynamically constructs node objects. As the parsing progresses from the bottom up, these nodes are linked together to form an **Abstract Syntax Tree (AST)**. 
- Every node represents a construct in the source code (e.g., `BinaryOpNode`, `VariableDeclNode`, `FunctionCallNode`).
- The AST strips away unnecessary punctuation and syntax details, leaving a pure hierarchical representation of the program's logic, ready for the next phase.

### 3. Semantic Analyzer
The Semantic Analyzer traverses the generated AST to enforce the rules of the language that cannot be caught by the CFG.
- **Symbol Table & Scope Management:** Implements a stack-based Symbol Table to manage global and local scopes. It handles variable shadowing and ensures variables/functions are declared before use.
- **Type Checking:** Strictly evaluates the types of expressions during AST traversal. It prevents illegal operations (e.g., assigning a string to an integer variable or adding a boolean to a float).
- **Function Validation:** Verifies that function calls match their definitions in terms of arguments and return types.

## üõ†Ô∏è Technologies & Tools
- **Python 3.x:** Core language.
- **PLY (Python Lex-Yacc):** Lexer and Parser generator.
- **Object-Oriented Programming (OOP):** Heavily used for AST node definitions and Symbol Table architecture.

## üìÇ Project Structure
- `lexer.py`: Token definitions and regex rules.
- `parser.py`: CFG rules, $LALR(1)$ parsing, and AST node construction logic.
- `semantic.py`: AST traversal, Symbol Table implementation, and type-checking logic.
- `main.py`: The orchestrator that chains the Lexer, Parser, and Semantic Analyzer.
- `tests/`: Contains sample source code files for testing the compiler.

## üíª How to Run

1. Clone the repository:
```bash
   git clone https://github.com/mehrshadk84/CompilerPython.git
   cd CompilerPython
```

2. Install dependencies:
```bash
   pip install ply
```
3. Run the compiler on a test file:
```bash
   python main.py tests/sample_code.txt
```
python main.py tests/sample_code.txt
   
##üéØ Example Pipeline Output
When a valid source file is processed, the compiler outputs the success of each phase:
```bash
text
Compiling tests/sample_code.txt...

Syntax OK ‚úÖ
AST Generation Successful üå≥
Semantic Analysis OK ‚úÖ

Compilation Successful! Ready for Intermediate Code Generation.

---
*Developed by [Mehrshad](https://github.com/mehrshadk84) as a deep dive into Compiler Design and Automata Theory.*


---
```